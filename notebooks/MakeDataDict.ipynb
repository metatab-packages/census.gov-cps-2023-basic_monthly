{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import metapack as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display \n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_context('notebook')\n",
    "mp.jupyter.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Current Population Survey, 2023</h1>\n",
       "<p><code>census.gov-cps-2023-basic_monthly-1.1.1</code> Last Update: 2023-02-24T21:00:55</p>\n",
       "<p>__</p>\n",
       "<h2>Documentation Links</h2>\n",
       "<ul>\n",
       "<li><a href=\"https://www.census.gov/programs-surveys/cps/technical-documentation/subject-definitions.html\">Subject Definitions</a> Descriptions of major concepts.</li>\n",
       "<li><a href=\"https://www.census.gov/programs-surveys/cps/technical-documentation/user-notes.html\">User Notes</a> Various technical documentation.</li>\n",
       "</ul>\n",
       "<h2>Contacts</h2>\n",
       "<ul>\n",
       "<li><strong>Wrangler</strong> <a href=\"mailto:eric@civicknowledge.com\">Eric Busboom</a>, <a href=\"http://civicknowledge.com\">Civic Knowledge</a></li>\n",
       "</ul>\n",
       "<h2>Resources</h2>\n",
       "<ul>\n",
       "<li><strong> <a href=\"notebooks/Extract.ipynb\">cps202301</a></strong>. </li>\n",
       "</ul>\n",
       "<h2>References</h2>\n",
       "<ul><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/jan23pub.csv\">jan23</a></strong>. January 2023</li><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/2023_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt\">data_dictionary</a></strong>. </li><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/jan23pub.csv\">cps202301_source</a></strong>. </li><ul>"
      ],
      "text/plain": [
       "# Current Population Survey, 2023\n",
       "`census.gov-cps-2023-basic_monthly-1.1.1` Last Update: 2023-02-24T21:00:55\n",
       "\n",
       "__\n",
       "\n",
       "\n",
       "## Documentation Links\n",
       "\n",
       "* [Subject Definitions](https://www.census.gov/programs-surveys/cps/technical-documentation/subject-definitions.html) Descriptions of major concepts.\n",
       "* [User Notes](https://www.census.gov/programs-surveys/cps/technical-documentation/user-notes.html) Various technical documentation.\n",
       "\n",
       " \n",
       "\n",
       "## Contacts\n",
       "\n",
       "* **Wrangler** [Eric Busboom](mailto:eric@civicknowledge.com), [Civic Knowledge](http://civicknowledge.com)\n",
       "\n",
       "## Resources\n",
       "\n",
       "* ** [cps202301](notebooks/Extract.ipynb)**. \n",
       "\n",
       "## References\n",
       "<ul><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/jan23pub.csv\">jan23</a></strong>. January 2023</li><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/2023_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt\">data_dictionary</a></strong>. </li><li> <strong><a href=\"https://www2.census.gov/programs-surveys/cps/datasets/2023/basic/jan23pub.csv\">cps202301_source</a></strong>. </li><ul>\n"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pkg = mp.jupyter.open_package()\n",
    "pkg = mp.jupyter.open_source_package()\n",
    "pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Volumes/SSD_Extern/metapack/www2.census.gov/programs-surveys/cps/datasets/2023/basic/2023_Basic_CPS_Public_Use_Record_Layout_plus_IO_Code_list.txt')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pkg.reference('data_dictionary')\n",
    "dd.resolved_url.get_resource().fspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pkg.reference('data_dictionary')\n",
    "with dd.resolved_url.get_resource().fspath.open(encoding='latin1') as f:\n",
    "    lines = f.readlines()\n",
    " \n",
    "end_line = next(i for i, l in enumerate(lines) if l.startswith('End of') )\n",
    "\n",
    "# Split out industry codes\n",
    "dd_lines = lines[:end_line]\n",
    "indst_code_lines = lines[end_line: ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELKLWO : WHEN LAST WORKED\n",
      "PXNLFRET : ALLOCATION FLAG\n",
      "PEERNHRY : HOURLY / NONHOURLY STATUS\n",
      "PRABSREA : REASON NOT AT WORK AND PAY STATUS\n",
      "PXNMEMP1 : ALLOCATION FLAG\n",
      "PEHRRSN3 : WHAT IS THE MAIN REASON YOU WORKED LESS THAN 35 HOURS LAST WEEK ?\n",
      "PXINUSYR : ALLOCATION FLAG\n",
      "PXHGCOMP : ALLOCATION FLAG\n",
      "PELAYFTO : FT / PT STATUS OF JOB FROM WHICH SAMPLE PERSON WAS ON LAYOFF FROM\n",
      "PUIOCK3 : I  &  O CHECK ITEM 3\n",
      "PESCHFT : ARE YOU ENROLLED IN SCHOOL AS A FULL - TIME OR PART - TIME STUDENT ?\n",
      "PRABSREA : REASON NOT AT WORK AND PAY STATUS\n",
      "PRCOW1 : CLASS OF WORKER RECODE  -  JOB 1\n",
      "PRFAMREL : FAMILY RELATIONSHIP RECODE\n",
      "PRNMCHLD : Number of own children  < 18 years of age\n",
      "GTCBSAST : PRINCIPAL CITY / BALANCE STATUS\n",
      "PXHRFTPT : ALLOCATION FLAG\n",
      "PTIO1OCD : OCCUPATION CODE FOR PRIMARY JOB .\n",
      "PEIO1ICD : INDUSTRY CODE FOR PRIMARY JOB\n",
      "PUIOCK1 : I  &  O CHECK ITEM 1 SCREEN FOR DEPENDENT I AND O\n",
      "PRUNEDUR : DURATION OF UNEMPLOYMENT FOR LAYOFF AND LOOKING RECORDS\n",
      "PXAFNOW : ALLOCATION FLAG\n",
      "PUHROFF2 : HOW MANY HOURS DID YOU TAKE OFF ?\n",
      "PEDISEYE : IS BLIND OR DOES HAVE SERIOUS DIFFICULTY SEEING EVEN WHEN WEARING GLASSES ?\n",
      "PXDWLKWK : ALLOCATION FLAG\n",
      "PTIO2OCD : OCCUPATION CODE FOR SECOND JOB .\n",
      "PRCHLD : PRESENCE OF OWN CHILDREN  < 18 YEARS OF AGE BY SELECTED AGE GROUP\n",
      "PESCHLVL : WOULD THAT BE HIGH SCHOOL ,  COLLEGE ,   OR UNIVERSITY ?\n",
      "PULKDK6 : SAME AS PULKDK2  ( SIXTH METHOD )\n",
      "PRMJOCC2 : MAJOR OCCUPATION RECODE  -  JOB 2\n"
     ]
    }
   ],
   "source": [
    "# Classify lines in the data dictionary \n",
    "\n",
    "import re\n",
    "\n",
    "def tok(l):\n",
    "    l = re.sub(r'\\t+', lambda m: f\" tabs{len(m[0])} \", l)\n",
    "    l = re.sub(r'\\s\\s\\s+', lambda m: f\" spaces{len(m[0])} \", l)\n",
    "    return [e for e in re.split(r'\\b', l.rstrip() ) if e not in  (' ','', '\\n')]\n",
    "\n",
    "\n",
    "\n",
    "def is_int(t):\n",
    "    try:\n",
    "        return str(int(t)) == str(t)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def shape(toks):\n",
    "    s = []\n",
    "    for t in toks:\n",
    "        if t.startswith('tabs'):\n",
    "            s.append('T')\n",
    "        elif all([e==' ' for e in t]) or t.startswith('spaces'):\n",
    "            s.append('S')\n",
    "        elif all([str.isdigit(e) for e in t]):\n",
    "            s.append('9')\n",
    "        elif t.strip() == '-':\n",
    "            s.append('-')\n",
    "        elif not all([str.isalnum(e) for e in t]):\n",
    "            s.append('.')\n",
    "        elif  all([str.isalnum(e) for e in t]):\n",
    "            s.append('A')\n",
    "        else:\n",
    "            s.append('?')\n",
    "            \n",
    "    return ''.join(s)\n",
    "     \n",
    "def is_variable_intro(s):\n",
    "    return (s.startswith('AT9') or s.startswith('ATS9')) and (s.endswith('9-9') or s.endswith('9.9') )\n",
    "    \n",
    "def is_categorical_value(s, var_name):\n",
    "    \"\"\"\n",
    "    'T9T9.9A' is for money lines ie, '5\t12,500 TO 14,999'\n",
    "    'T9.A' is for an error in the formating, ie, '1 = Asian Indian' for PRDASIAN\n",
    "    'T9AA' is for GEDIV, ie '1 NEW ENGLAND'\n",
    "    'T9T9.9' is for GTCBSASZ, ie, 2\t100,000 - 249,999\n",
    "    'T9T9-9' is for PRINUSYR, '02\t1950-1959'\n",
    "    \n",
    "    \n",
    "    There are other errors in the file: \n",
    "    \n",
    "        GESTFIPS is in a two column format. \n",
    "    \"\"\"\n",
    "        \n",
    "    return re.match(r'[TS]+9[TS]+A', s) \\\n",
    "        or s.startswith('T9T9.9A') \\\n",
    "        or s.startswith('T9.A')  \\\n",
    "        or s.startswith('T9AA') \\\n",
    "        or s.startswith('T9T9.9') \\\n",
    "        or s.startswith('T9T9-9') or s.startswith('T9ST9-9')\n",
    "\n",
    "\n",
    "def is_universe(l):\n",
    "    return 'EDITED UNIVERSE' in l\n",
    "\n",
    "def is_cat_intro(l):\n",
    "    \"\"\"The VALID ENTRIES LINE\"\"\"\n",
    "    \n",
    "    return 'VALID ENTRIES' in l\n",
    "  \n",
    "def categorize_line(l, var_name):\n",
    "    \n",
    "    if 'FILLER' in l:\n",
    "        return \"FIL\"\n",
    "\n",
    "    t = tok(l)\n",
    "    s = shape(t)\n",
    "\n",
    "  \n",
    "    if not t:\n",
    "        return \"NIL\"\n",
    "\n",
    "    elif is_variable_intro(s):\n",
    "        return 'VAR'\n",
    "    elif is_categorical_value(s, var_name):\n",
    "        return 'CAT'\n",
    "    elif is_cat_intro(l):\n",
    "        return 'VE' # \"Valid Entries\"\n",
    "    elif is_universe(l):\n",
    "        return 'EU' # \"Edited Universe\"\n",
    "    else:\n",
    "        return 'UNK'\n",
    "\n",
    "    \n",
    "def debug_dump(lines):\n",
    "    \"\"\"Print out the data dict file for debugging \"\"\"\n",
    "    \n",
    "    from colorama import Fore, Back, Style\n",
    "    var_name = None\n",
    "    \n",
    "    for l in lines:\n",
    "\n",
    "        c = categorize_line(l, None)\n",
    "        \n",
    "        if c == 'VAR':\n",
    "            toks = tok(l)\n",
    "            try:\n",
    "                var_name, size, *text, start, _, end = filter_line(toks)\n",
    "                var_desc = ' '.join(text)\n",
    "            except ValueError as e:\n",
    "                print(\"ERROR\",e,l)\n",
    "        \n",
    "        if c == 'NIL':\n",
    "            continue\n",
    "        elif c == 'UNK':\n",
    "            pre = Fore.RED + shape(tok(l)) + Style.RESET_ALL\n",
    "        else:\n",
    "            pre = str.ljust(c, 8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(pre, l.rstrip())\n",
    "        \n",
    "def filter_line(toks):\n",
    "    \"\"\"Remove tab and space tokens\"\"\"\n",
    "    \n",
    "    def remove_f(v):\n",
    "        if v.startswith('tabs') or v.startswith('spaces'):\n",
    "            return True\n",
    "        \n",
    "        if not v.strip():\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    return [ t for t in toks if not remove_f(t) ]\n",
    "        \n",
    "def process(lines):  \n",
    "    \n",
    "    from collections import defaultdict\n",
    "    \n",
    "    vard = {} # Var descriptions\n",
    "    vvd = defaultdict(dict) # var-val descriptions\n",
    "    \n",
    "    in_var = False # Send var name line, but note var values\n",
    "    in_cat = False # Seen first var value, but not next var name\n",
    "    \n",
    "    var_name  = None\n",
    "    var_val = None\n",
    "    \n",
    "    for i, l in enumerate(lines):\n",
    "        c = categorize_line(l, var_name)\n",
    "        toks = tok(l)\n",
    "\n",
    "        if c == 'VAR':\n",
    "            in_var = True \n",
    "            in_cat = False\n",
    "            try:\n",
    "                var_name, size, *text, start, _, end = filter_line(toks)\n",
    "                var_desc = ' '.join(text)\n",
    "                vard[var_name] = var_desc\n",
    "            except ValueError:\n",
    "                print(i, l)\n",
    "                print(toks)\n",
    "                print(filter_line(toks))\n",
    "                raise\n",
    "        elif c in ('VE','EU'):\n",
    "            in_var = False \n",
    "            in_cat = False\n",
    "    \n",
    "        elif c == 'CAT':\n",
    "            in_var = False \n",
    "            in_cat = True\n",
    "            \n",
    "            var_val, *text = filter_line(toks)\n",
    "            \n",
    "            val_desc = ' '.join(text)\n",
    "            \n",
    "            try:\n",
    "                vvd[var_name][int(var_val)] = val_desc.strip('= ')\n",
    "                \n",
    "            except ValueError:\n",
    "                print(\"ERROR, CAT\", c, var_name, \"|\", var_val.strip(), \"|\", val_desc.strip())\n",
    "            \n",
    "        elif var_name is not None: # continuation lines\n",
    "            text = ' '.join(filter_line(toks))\n",
    "            \n",
    "            if in_var:\n",
    "                vard[var_name] = (vard[var_name] +\" \"+text).strip()\n",
    "            elif in_cat:\n",
    "                vvd[var_name][int(var_val)] = (vvd[var_name][int(var_val)]+\" \"+text).strip()\n",
    "                    \n",
    "            elif len(toks):\n",
    "                pass\n",
    "                # These are notes, but also sometime text that ought to be attached to the\n",
    "                # record\n",
    "                #print(\"ERROR, Cont Line\", i,  toks)\n",
    "        \n",
    "            \n",
    "    return vvd, vard\n",
    "  \n",
    "vvd, vard = process(dd_lines)\n",
    "\n",
    "import pandas as pd\n",
    "var_vals = pd.DataFrame([ dict(column=var_name.lower(), var_val=var_val, desc=desc) for var_name, v in vvd.items() for var_val, desc in v.items()])\n",
    "var_vals\n",
    "\n",
    "from random import choices\n",
    "\n",
    "for k,v in choices(list(vard.items()), k=30):\n",
    "    print(k,\":\",v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535ce94917c045798ad607aaf8613727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aac584dc87c4ba1b18bef3043d992df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use OpenAi to re-write the variable descriptions\n",
    "prompt = \"\"\"\n",
    "You will clean up text by performing the following operations\n",
    "\n",
    "- Organize the text into full English sentences, with propery capitalization and punctuation\n",
    "- Fix gramatical errors.\n",
    "- Turn sentence fragments into full sentences\n",
    "- Remove any words or other characters that can be included in a sentence. \n",
    "\n",
    "Here the lines of text to clean up. The first word of each line, before the \":\" is the variable name, and the text after the \":\" is the text you should clean up. In your output, \n",
    "print each variable name, then \":\", then the cleaned up text. \n",
    "\n",
    "{text_lines} \"\"\"\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def openai_one_completion(prompt):\n",
    "    \"\"\"Call the OpenAI completions interface to re-write the extra path for a census variable\n",
    "    into an English statement that can be used to describe the variable.\"\"\"\n",
    "\n",
    "    import os\n",
    "    import openai\n",
    "\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=2048,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.2,\n",
    "        presence_penalty=0.2,\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "def update_vard():\n",
    "    \"\"\"Call Open AI to clean the descriptions\"\"\"\n",
    "    \n",
    "    \n",
    "    text_lines = ''\n",
    "\n",
    "    from more_itertools import chunked\n",
    "\n",
    "    chunks = list(chunked(list(vard.items()), n=20))\n",
    "\n",
    "    resp = []\n",
    "\n",
    "    for chunk in tqdm(chunks):\n",
    "        text_lines = '\\n'.join([ k+\":\"+v for k, v in chunk])\n",
    "        p = prompt.format(text_lines=text_lines)\n",
    "\n",
    "        resp.append(openai_one_completion(p))\n",
    "\n",
    "    upd_vard = {}\n",
    "\n",
    "    from itertools import chain\n",
    "    for g in tqdm(list(chain(resp))):\n",
    "        for line in g.splitlines():\n",
    "            try:\n",
    "                k, v = line.split(':',1)\n",
    "                upd_vard[k] = v\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "            \n",
    "    return upd_vard\n",
    "\n",
    "if not \"upd_vard\" in list(locals()):\n",
    "    upd_vard = update_vard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hrhhid</td>\n",
       "      <td>Household Identifier (Part 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hrmonth</td>\n",
       "      <td>Month of Interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hryear4</td>\n",
       "      <td>Year of Interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hurespli</td>\n",
       "      <td>Line Number of the Current Respondent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hufinal</td>\n",
       "      <td>Final Outcome Code Outcome codes between 001 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>prdasian</td>\n",
       "      <td>Detailed Asian race recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>pepdemp1</td>\n",
       "      <td>Does this person usually have any paid employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>ptnmemp1</td>\n",
       "      <td>Excluding all owners, how many paid employees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>pepdemp2</td>\n",
       "      <td>Does this person usually have any paid employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>ptnmemp2</td>\n",
       "      <td>Excluding all owners, how many paid employees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       column                                               desc\n",
       "0      hrhhid                     Household Identifier (Part 1) \n",
       "1     hrmonth                                Month of Interview \n",
       "2     hryear4                                 Year of Interview \n",
       "3    hurespli             Line Number of the Current Respondent \n",
       "4     hufinal   Final Outcome Code Outcome codes between 001 ...\n",
       "..        ...                                                ...\n",
       "375  prdasian                        Detailed Asian race recode \n",
       "376  pepdemp1   Does this person usually have any paid employ...\n",
       "377  ptnmemp1   Excluding all owners, how many paid employees...\n",
       "378  pepdemp2   Does this person usually have any paid employ...\n",
       "379  ptnmemp2   Excluding all owners, how many paid employees...\n",
       "\n",
       "[380 rows x 2 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = [ dict(column=k.lower(), desc=v) for k,v in upd_vard.items()]\n",
    "dd = pd.DataFrame(rows)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>var_val</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hrmonth</td>\n",
       "      <td>1</td>\n",
       "      <td>MIN VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hrmonth</td>\n",
       "      <td>12</td>\n",
       "      <td>MAX VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hryear4</td>\n",
       "      <td>1998</td>\n",
       "      <td>MIN VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hryear4</td>\n",
       "      <td>2999</td>\n",
       "      <td>MAX VALUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hurespli</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN VALUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column  var_val       desc\n",
       "0   hrmonth        1  MIN VALUE\n",
       "1   hrmonth       12  MAX VALUE\n",
       "2   hryear4     1998  MIN VALUE\n",
       "3   hryear4     2999  MAX VALUE\n",
       "4  hurespli        0  MIN VALUE"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_vals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv('../data/variable_descriptions.csv', index=False)\n",
    "var_vals.to_csv('../data/variable_values.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
